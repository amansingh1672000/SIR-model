{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0qXFr5KAa6"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "import torch\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import Planetoid,WebKB\n",
        "import torch_geometric.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_cora_network():\n",
        "    #Based on your requirement give the path of the datasets\n",
        "    dataset = WebKB(root='data/WebKB', name='Wisconsin', transform=T.NormalizeFeatures())\n",
        "    data = dataset[0]\n",
        "\n",
        "    # Convert to NetworkX graph\n",
        "    edge_index = data.edge_index.numpy()\n",
        "    edges = list(zip(edge_index[0], edge_index[1]))\n",
        "    G = nx.Graph()\n",
        "    G.add_edges_from(edges)\n",
        "    return G\n",
        "\n",
        "def sir_simulation(G, seed_node, beta, gamma=0.2, max_time=100):\n",
        "    \"\"\"\n",
        "    Run a single SIR simulation starting from a seed node.\n",
        "\n",
        "    Parameters:\n",
        "    - G: NetworkX graph\n",
        "    - seed_node: Starting node for infection\n",
        "    - beta: Infection rate\n",
        "    - gamma: Recovery rate\n",
        "    - max_time: Maximum simulation steps\n",
        "\n",
        "    Returns:\n",
        "    - final_infected_count: Number of nodes that were infected during simulation\n",
        "    \"\"\"\n",
        "    N = G.number_of_nodes()\n",
        "\n",
        "    # Initialize states (0: Susceptible, 1: Infected, 2: Recovered)\n",
        "    states = np.zeros(N)\n",
        "    states[seed_node] = 1\n",
        "\n",
        "    infected = {seed_node}\n",
        "    recovered = set()\n",
        "\n",
        "    for _ in range(max_time):\n",
        "        if not infected:\n",
        "            break\n",
        "\n",
        "        # Process infections\n",
        "        new_infected = set()\n",
        "        for node in infected:\n",
        "            # Try to infect neighbors\n",
        "            for neighbor in G.neighbors(node):\n",
        "                if states[neighbor] == 0 and np.random.random() < beta:\n",
        "                    new_infected.add(neighbor)\n",
        "                    states[neighbor] = 1\n",
        "\n",
        "            # Process recovery\n",
        "            if np.random.random() < gamma:\n",
        "                recovered.add(node)\n",
        "                states[node] = 2\n",
        "\n",
        "        # Update infected set\n",
        "        infected = infected.union(new_infected) - recovered\n",
        "\n",
        "    return len(recovered.union(infected))\n",
        "\n",
        "def calculate_discrimination(G, beta, num_simulations=100, top_fraction=0.1):\n",
        "    \"\"\"\n",
        "    Calculate discrimination metric D for a given infection rate beta.\n",
        "\n",
        "    Parameters:\n",
        "    - G: NetworkX graph\n",
        "    - beta: Infection rate to test\n",
        "    - num_simulations: Number of SIR simulations per node\n",
        "    - top_fraction: Fraction of nodes to consider as high influence group\n",
        "\n",
        "    Returns:\n",
        "    - D: Discrimination metric value\n",
        "    - influence_capacities: List of influence capacities for each node\n",
        "    \"\"\"\n",
        "    N = G.number_of_nodes()\n",
        "    nodes = list(G.nodes())\n",
        "\n",
        "    # Calculate influence capacity for each node\n",
        "    influence_capacities = []\n",
        "    for node in tqdm(nodes, desc=f\"Testing beta={beta:.2f}\"):\n",
        "        node_influence = 0\n",
        "        for _ in range(num_simulations):\n",
        "            infected_count = sir_simulation(G, node, beta)\n",
        "            node_influence += infected_count\n",
        "        influence_capacities.append(node_influence / num_simulations)\n",
        "\n",
        "    # Sort nodes by influence capacity\n",
        "    sorted_capacities = sorted(influence_capacities, reverse=True)\n",
        "\n",
        "    # Calculate parameters for discrimination metric\n",
        "    n_top = int(N * top_fraction)\n",
        "    CH = sum(sorted_capacities[:n_top])\n",
        "    CL = sum(sorted_capacities[n_top:])\n",
        "    H = sorted_capacities[0]\n",
        "    L = sorted_capacities[-1]\n",
        "\n",
        "    # Calculate discrimination metric D\n",
        "    D = (CH - CL) / (n_top * (H - L))\n",
        "\n",
        "    return D, influence_capacities\n",
        "\n",
        "def find_optimal_beta(G, beta_range=None):\n",
        "    \"\"\"\n",
        "    Find the optimal infection rate beta that maximizes discrimination.\n",
        "\n",
        "    Parameters:\n",
        "    - G: NetworkX graph\n",
        "    - beta_range: Range of beta values to test\n",
        "\n",
        "    Returns:\n",
        "    - optimal_beta: Beta value that maximizes discrimination\n",
        "    - max_D: Maximum discrimination value achieved\n",
        "    - best_influences: Influence capacities for each node at optimal beta\n",
        "    \"\"\"\n",
        "    if beta_range is None:\n",
        "        beta_range = np.arange(0.1, 1.0,0.2)\n",
        "\n",
        "    results = []\n",
        "    best_influences = None\n",
        "\n",
        "    for beta in beta_range:\n",
        "        D, influences = calculate_discrimination(G, beta)\n",
        "        results.append((beta, D, influences))\n",
        "        print(f\"Beta: {beta:.1f}, Discrimination: {D:.4f}\")\n",
        "\n",
        "    optimal_beta, max_D, best_influences = max(results, key=lambda x: x[1])\n",
        "    return optimal_beta, max_D, best_influences\n",
        "\n",
        "def main():\n",
        "    # Load Cora network\n",
        "    print(\"Loading Cora dataset...\")\n",
        "    G = load_cora_network()\n",
        "    print(f\"Loaded Cora network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
        "\n",
        "    # Find optimal infection rate\n",
        "    print(\"\\nFinding optimal infection rate...\")\n",
        "    optimal_beta, max_D, best_influences = find_optimal_beta(G)\n",
        "\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"Optimal infection rate (beta): {optimal_beta:.2f}\")\n",
        "    print(f\"Maximum discrimination value: {max_D:.4f}\")\n",
        "\n",
        "    # Get top influential nodes\n",
        "    node_influences = list(enumerate(best_influences))\n",
        "    top_nodes = sorted(node_influences, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    print(\"\\nTop 10 most influential nodes:\")\n",
        "    for node_id, influence in top_nodes:\n",
        "        print(f\"Node {node_id}: Influence capacity = {influence:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}